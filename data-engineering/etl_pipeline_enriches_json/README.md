# ETL Pipeline: Geocode JSON with LocationIQ & Airflow

A lightweight ETL that reads raw JSON, enriches each record with latitude/longitude via LocationIQ (free version to test), and writes out an enriched JSONâ€”fully orchestrated by Apache Airflow and Docker Compose.

---

## ðŸš€ Background

In modern ETL you often need to augment datasets with thirdâ€‘party geocoding. This project demonstrates a productionâ€‘grade pattern:

1. **Extract** â€“ read `input_sample.json`  
2. **Transform** â€“ call LocationIQ API with retries/backoff and schema checks 
3. **Load** â€“ dump enriched JSON  
4. **Orchestrate** â€“ Airflow DAG with collapsible ETL task group  
5. **Test** â€“ unit tests via `pytest` in a container

---

## âœ¨ Features

- **Robust Geocoding** using LocationIQ free tier (sign up and put the key in Airflow variable)
- **Retries & Exponential Backoff** (viaâ€¯`tenacity`) on API failures  
- **Schema Validation & Structured Logging** for empty or malformed payloads  
- **Airflow DAG** with  `TaskGroup` for extractâ†’transformâ†’load  
- **Comprehensive Unit Tests** (`pytest`) run in their own Docker service  
- **Containerâ€‘native**: Airflow, Postgres, Redis, and test runner all defined in `docker-compose.yml`  

---

## ðŸ“¦ Prerequisites

- **Docker**â€¯>=â€¯28 
- **Docker Compose**â€¯>=â€¯v2.25.0 

---

## ðŸ”§ Quickstart

1. **Clone**  
   ```bash
   git clone https://github.com/ycmy28/ycmy28_project.git

2. **Bring up Airflow infra**  
   ```initialize DB & create admin user
    docker compose up airflow-init

    ```initialize DB & create admin user
    docker compose up -d

3. **Configure Airflow Variable**  
   ```In the Airflow UI (http://localhost:8080 â†’ Admin â†’ Variables), add:
    Key:   LOCATIONIQ_KEY
    Value: pk.your_actual_key_here

4. **Running Unit Tests**  
   ```# optional: start Postgres & Redis, if not already running
    docker compose up -d postgres redis

    ```# run tests in a temporary container
    docker compose run --rm pytest

Cleanup:
docker compose down --volumes --rmi all

## Project Structure
etl_pipeline_enriches_json/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ geocode_pipeline.py       # Airflow DAG
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ int_test_input/
â”‚   â”‚   â””â”€â”€ input_sample.json     # sample raw data
â”‚   â””â”€â”€ int_test_output/          # enriched output
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ integrations/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ geocode_util.py       # geocoding utils
â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ address_transformer.py# enrich logic
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ reader.py             # JSON reader
â”‚       â””â”€â”€ writer.py             
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_geocode.py
â”‚   â”œâ”€â”€ test_reader.py
â”‚   â”œâ”€â”€ test_writer.py
â”‚   â””â”€â”€ test_transformer.py
â”œâ”€â”€ requirements.txt              # runtime dependencies
â”œâ”€â”€ requirements-dev.txt          # pytest, tenacity, etc.
â”œâ”€â”€ setup.py                      # for `pip install -e .`
â””â”€â”€ docker-compose.yml            # service definitions


## License

This project is open-sourced under the [MIT License](LICENSE).

---

Proudly maintained by Yudha, driven by data and inspired by possibilities.
